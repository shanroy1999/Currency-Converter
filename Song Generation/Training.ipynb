{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_FILE_DATASET = \"C:/Users/Lenovo/Desktop/New folder/python/Song Generation/file_dataset\"\n",
    "SEQUENCE_LENGTH = 64\n",
    "MAPPING_PATH = \"C:/Users/Lenovo/Desktop/New folder/python/Song Generation/mapping.json\"\n",
    "OUTPUT_UNITS = 38\n",
    "LOSS = \"sparse_categorical_crossentropy\"\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_UNITS = [256]\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "SAVE_MODEL_PATH = \"C:/Users/Lenovo/Desktop/New folder/python/Song Generation/model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        song = f.read()\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_songs_to_int(songs):\n",
    "    int_songs = []\n",
    "    \n",
    "    # load the mappings\n",
    "    with open(MAPPING_PATH, \"r\") as f:\n",
    "        mappings = json.load(f)\n",
    "    \n",
    "    # cast song string to a list\n",
    "    songs = songs.split()\n",
    "\n",
    "    # map songs to int\n",
    "    for symbol in songs:\n",
    "        int_songs.append(mappings[symbol])\n",
    "    \n",
    "    return int_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_sequences(sequence_length):\n",
    "    # [11, 12, 13, 14, ....], => (input1 = [11, 12] , target1 = [13]) ; (input2 = [12, 13], target2 = [14])\n",
    "    # network => predict the next item in the time sequence, predict the next musical note given the historical melody\n",
    "    # LSTM => able to understand memory wise the next event in melody given the historical melody as input\n",
    "    \n",
    "    # Load the songs and map them to intergers\n",
    "    songs = load(SINGLE_FILE_DATASET)\n",
    "    int_songs = convert_songs_to_int(songs)\n",
    "    \n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    # Generate the training sequences\n",
    "    # sequences length = 64, total symbols = 100 => no of sequences = 100-64 = 36\n",
    "    num_sequences = len(int_songs) - sequence_length\n",
    "    for i in range(num_sequences):\n",
    "        inputs.append(int_songs[i:i+sequence_length])\n",
    "        targets.append(int_songs[i+sequence_length])\n",
    "    \n",
    "    # inputs => (no of sequences, sequence_length)\n",
    "    \n",
    "    # One-hot encode the sequences to deal with the categorical data\n",
    "    # inputs get an extra dimension => inputs => (no of sequences, sequence_length, vocab_size) => 3D array\n",
    "    vocab_size = len(set(int_songs))\n",
    "    inputs = keras.utils.to_categorical(inputs, num_classes = vocab_size)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(output_units, num_units, loss, learning_rate):\n",
    "    \n",
    "    # create model architecture\n",
    "    +  \n",
    "    input = keras.layers.Input(shape=(None, output_units))\n",
    "    x = keras.layers.LSTM(num_units[0])(input)                   # Passing the input to the LSTM layer using functional API\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    output = keras.layers.Dense(output_units, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = keras.Model(input, output)\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "        metrics = ['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(output_units=OUTPUT_UNITS, num_units=NUM_UNITS, loss=LOSS, learning_rate=LEARNING_RATE):\n",
    "    \n",
    "    # generate the training sequences\n",
    "    inputs, targets = generate_training_sequences(SEQUENCE_LENGTH)\n",
    "    \n",
    "    # build the network\n",
    "    model = build_model(output_units, num_units, loss, learning_rate)\n",
    "    \n",
    "    # train the network\n",
    "    model.fit(inputs, targets, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # save the model\n",
    "    model.save(SAVE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 38)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               302080    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 38)                9766      \n",
      "=================================================================\n",
      "Total params: 311,846\n",
      "Trainable params: 311,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "362402/362402 [==============================] - 1446s 4ms/step - loss: 0.6832 - accuracy: 0.7885\n",
      "Epoch 2/50\n",
      "362402/362402 [==============================] - 578s 2ms/step - loss: 0.5824 - accuracy: 0.8110\n",
      "Epoch 3/50\n",
      "362402/362402 [==============================] - 1049s 3ms/step - loss: 0.5586 - accuracy: 0.8206s\n",
      "Epoch 4/50\n",
      "362402/362402 [==============================] - 604s 2ms/step - loss: 0.5297 - accuracy: 0.8285\n",
      "Epoch 5/50\n",
      "362402/362402 [==============================] - 585s 2ms/step - loss: 0.5169 - accuracy: 0.8321\n",
      "Epoch 6/50\n",
      "362402/362402 [==============================] - 565s 2ms/step - loss: 0.5063 - accuracy: 0.8360\n",
      "Epoch 7/50\n",
      "362402/362402 [==============================] - 619s 2ms/step - loss: 0.4873 - accuracy: 0.8407\n",
      "Epoch 8/50\n",
      "362402/362402 [==============================] - 634s 2ms/step - loss: 0.4740 - accuracy: 0.8444\n",
      "Epoch 9/50\n",
      "362402/362402 [==============================] - 638s 2ms/step - loss: 0.4580 - accuracy: 0.8494\n",
      "Epoch 10/50\n",
      "362402/362402 [==============================] - 640s 2ms/step - loss: 0.4493 - accuracy: 0.8517\n",
      "Epoch 11/50\n",
      "362402/362402 [==============================] - 634s 2ms/step - loss: 0.4306 - accuracy: 0.8575\n",
      "Epoch 12/50\n",
      "362402/362402 [==============================] - 641s 2ms/step - loss: 0.4217 - accuracy: 0.8604\n",
      "Epoch 13/50\n",
      "362402/362402 [==============================] - 660s 2ms/step - loss: 0.4123 - accuracy: 0.8633\n",
      "Epoch 14/50\n",
      "362402/362402 [==============================] - 643s 2ms/step - loss: 0.4005 - accuracy: 0.8669\n",
      "Epoch 15/50\n",
      "362402/362402 [==============================] - 632s 2ms/step - loss: 0.3930 - accuracy: 0.8698\n",
      "Epoch 16/50\n",
      "362402/362402 [==============================] - 616s 2ms/step - loss: 0.3869 - accuracy: 0.8710\n",
      "Epoch 17/50\n",
      "362402/362402 [==============================] - 571s 2ms/step - loss: 0.3783 - accuracy: 0.8739\n",
      "Epoch 18/50\n",
      "362402/362402 [==============================] - 596s 2ms/step - loss: 0.3656 - accuracy: 0.8777\n",
      "Epoch 19/50\n",
      "362402/362402 [==============================] - 595s 2ms/step - loss: 0.3623 - accuracy: 0.8788\n",
      "Epoch 20/50\n",
      "362402/362402 [==============================] - 602s 2ms/step - loss: 0.3522 - accuracy: 0.8820\n",
      "Epoch 21/50\n",
      "362402/362402 [==============================] - 600s 2ms/step - loss: 0.3446 - accuracy: 0.8842\n",
      "Epoch 22/50\n",
      "362402/362402 [==============================] - 575s 2ms/step - loss: 0.3405 - accuracy: 0.8860\n",
      "Epoch 23/50\n",
      "362402/362402 [==============================] - 574s 2ms/step - loss: 0.3357 - accuracy: 0.8863\n",
      "Epoch 24/50\n",
      "362402/362402 [==============================] - 576s 2ms/step - loss: 0.3340 - accuracy: 0.8879\n",
      "Epoch 25/50\n",
      "362402/362402 [==============================] - 585s 2ms/step - loss: 0.3332 - accuracy: 0.8875\n",
      "Epoch 26/50\n",
      "362402/362402 [==============================] - 583s 2ms/step - loss: 0.3163 - accuracy: 0.8932\n",
      "Epoch 27/50\n",
      "362402/362402 [==============================] - 585s 2ms/step - loss: 0.3174 - accuracy: 0.8925\n",
      "Epoch 28/50\n",
      "362402/362402 [==============================] - 585s 2ms/step - loss: 0.3368 - accuracy: 0.8876\n",
      "Epoch 29/50\n",
      "362402/362402 [==============================] - 575s 2ms/step - loss: 0.3257 - accuracy: 0.8920\n",
      "Epoch 30/50\n",
      "362402/362402 [==============================] - 590s 2ms/step - loss: 0.3353 - accuracy: 0.8897\n",
      "Epoch 31/50\n",
      "362402/362402 [==============================] - 587s 2ms/step - loss: 0.3356 - accuracy: 0.8897\n",
      "Epoch 32/50\n",
      "362402/362402 [==============================] - 598s 2ms/step - loss: 0.3350 - accuracy: 0.8899\n",
      "Epoch 33/50\n",
      "362402/362402 [==============================] - 588s 2ms/step - loss: 0.3228 - accuracy: 0.8933\n",
      "Epoch 34/50\n",
      "362402/362402 [==============================] - 600s 2ms/step - loss: 0.3180 - accuracy: 0.8937\n",
      "Epoch 35/50\n",
      "362402/362402 [==============================] - 616s 2ms/step - loss: 0.3006 - accuracy: 0.8983\n",
      "Epoch 36/50\n",
      "362402/362402 [==============================] - 590s 2ms/step - loss: 0.2999 - accuracy: 0.8984\n",
      "Epoch 37/50\n",
      "362402/362402 [==============================] - 595s 2ms/step - loss: 0.3098 - accuracy: 0.8972\n",
      "Epoch 38/50\n",
      "362402/362402 [==============================] - 572s 2ms/step - loss: 0.3098 - accuracy: 0.8961\n",
      "Epoch 39/50\n",
      "362402/362402 [==============================] - 587s 2ms/step - loss: 0.2983 - accuracy: 0.8988\n",
      "Epoch 40/50\n",
      "362402/362402 [==============================] - 590s 2ms/step - loss: 0.2943 - accuracy: 0.9001\n",
      "Epoch 41/50\n",
      "362402/362402 [==============================] - 585s 2ms/step - loss: 0.2901 - accuracy: 0.9014\n",
      "Epoch 42/50\n",
      "362402/362402 [==============================] - 604s 2ms/step - loss: 0.2836 - accuracy: 0.9033\n",
      "Epoch 43/50\n",
      "362402/362402 [==============================] - 588s 2ms/step - loss: 0.2787 - accuracy: 0.9051\n",
      "Epoch 44/50\n",
      "362402/362402 [==============================] - 598s 2ms/step - loss: 0.2753 - accuracy: 0.9062\n",
      "Epoch 45/50\n",
      "362402/362402 [==============================] - 586s 2ms/step - loss: 0.2759 - accuracy: 0.9062\n",
      "Epoch 46/50\n",
      "362402/362402 [==============================] - 595s 2ms/step - loss: 0.2697 - accuracy: 0.9082\n",
      "Epoch 47/50\n",
      "362402/362402 [==============================] - 2038s 6ms/step - loss: 0.2670 - accuracy: 0.9093\n",
      "Epoch 48/50\n",
      "362402/362402 [==============================] - 1077s 3ms/step - loss: 0.2590 - accuracy: 0.9112\n",
      "Epoch 49/50\n",
      "362402/362402 [==============================] - 628s 2ms/step - loss: 0.2606 - accuracy: 0.9109\n",
      "Epoch 50/50\n",
      "362402/362402 [==============================] - 587s 2ms/step - loss: 0.2644 - accuracy: 0.9100\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
